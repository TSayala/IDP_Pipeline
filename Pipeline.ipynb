{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import os\n",
    "from pytictoc import TicToc\n",
    "import pandas as pd\n",
    "from documentProcessor import processAllDocuments, getLogger, fetchFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = getLogger()\n",
    "t = TicToc()\n",
    "core_constraint = [2, 3, 4, 5, 6, 7]\n",
    "psutil.Process(os.getpid()).cpu_affinity(core_constraint)\n",
    "logger.debug(f\"Initializing Document Classification Pipeline\")\n",
    "logger.info(f\"CPU affinity set to cores {core_constraint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#registerExtensions()\n",
    "#analyzer = UnsupervisedDocumentAnalyzer()\n",
    "#classifier = supervisedDocumentAnalyzer()\n",
    "#logger.info('DocumentAnalyzer initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsExamples = 'fewShot.csv'\n",
    "folder = 'testDir' # Set the folder to process\n",
    "directory = 'data/' + folder + '/'\n",
    "tif_files = fetchFiles(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.tic()\n",
    "logger.info(f'Starting document processing for {len(tif_files)} files in {directory}')\n",
    "\n",
    "results_df = processAllDocuments(tif_files, fsExamples, force_reload=False)\n",
    "\n",
    "elapsed_time = t.tocvalue()\n",
    "logger.info(f'Finished document processing for {len(tif_files)} files in {directory}. Time taken: {elapsed_time:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" print(f'Total documents processed: {len(results_df)}')\n",
    "print(f'Successfully processed: {results_df['status'].value_counts().get(\"success\", 0)}')\n",
    "print(f'Failed to process: {results_df['status'].value_counts().get(\"error\", 0)}')\n",
    "\n",
    "print(f'Category distribution:')\n",
    "print(results_df[results_df['status'] == 'success']['category'].value_counts())\n",
    "\n",
    "print(f'Average confidence: {results_df[results_df['status'] == 'success']['confidence'].mean():.2f}') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'error' in results_df['status'].values:\n",
    "  print('\\nError Analysis:')\n",
    "  error_df = results_df[results_df['status'] == 'error']\n",
    "  print(error_df['error_message'].value_counts())\n",
    "\n",
    "  print('\\nFiles with empty extracted text:')\n",
    "  empty_text_files = error_df[error_df['error_message'] == 'ValueError: Extracted text is empty']\n",
    "  print(empty_text_files['file_path'].tolist())\n",
    "\n",
    "  print('\\nFiles with other errors:')\n",
    "  other_error_files = error_df[error_df['error_message'] != 'ValueError: Extracted text is empty']\n",
    "  for _, row in other_error_files.iterrows():\n",
    "    print(f'File: {row[\"file_path\"]}')\n",
    "    print(f'Error: {row[\"error_message\"]}')\n",
    "    print(f'Extracted text length: {row['text_length']}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.value_counts('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('fewShot.csv')\n",
    "test.value_counts('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if a document is referral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isReferral(text):\n",
    "  referral_keywords = ['referral to', 'referral communication form', 'end of referral report', 'patient demo']\n",
    "  return any(keyword in text.lower() for keyword in referral_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def summarize(self, text):\n",
    "    try:\n",
    "      if not text or len(text) < 30:\n",
    "        logger.warning(f'Text length is less than 30 characters. Skipping summarization')\n",
    "        return text\n",
    "      \n",
    "      max_tokens = self.summarizer.tokenizer.model_max_length - 100\n",
    "      encoded_text = self.summarizer.tokenizer.encode(text, truncation=True, max_length=max_tokens)\n",
    "      decoded_text = self.summarizer.tokenizer.decode(encoded_text, skip_special_tokens=True)\n",
    "      logger.debug(f'Attempting to summarize text of length {len(decoded_text)}')\n",
    "\n",
    "      chunk_size = 1024\n",
    "      chunks = [decoded_text[i:i+chunk_size] for i in range(0, len(decoded_text), chunk_size)]\n",
    "\n",
    "      summaries = []\n",
    "      for chunk in chunks:\n",
    "        chunk_summary = self.summarizer(chunk, max_length=150, min_length=30, do_sample=False)\n",
    "        summaries.append(chunk_summary[0]['summary_text'])\n",
    "\n",
    "      final_summary = \" \".join(summaries)\n",
    "      if len(final_summary.split()) > 150:\n",
    "        final_summary = self.summarizer(final_summary, max_length=150, min_length=30, do_sample=False)[0]['summary_text']\n",
    "\n",
    "      logger.debug(f'Summary successful. Summary length: {len(final_summary)} characters')\n",
    "      return final_summary\n",
    "    \n",
    "    except Exception as e:\n",
    "      logger.error(f'Error in summarization: {str(e)}')\n",
    "      return text \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
